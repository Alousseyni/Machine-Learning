{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8deafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library of Functions for the OpenClassrooms Supervised Learning Course\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import graphviz \n",
    "from sklearn import tree\n",
    "\n",
    "def classComparePlot(df, class_name, plotType='density'):\n",
    "    '''Show comparative plots comparing the distribution of each feature for each class.  plotType can be 'density' or 'hist' '''\n",
    "\n",
    "    # Get the parameters for the plots\n",
    "    numcols = len(df.columns) - 1\n",
    "    unit_size = 5\n",
    "    classes = df[class_name].nunique()           # no of uniques classes\n",
    "    class_values = df[class_name].unique()       # unique class values\n",
    "\n",
    "    print('Comparative histograms for',class_values)\n",
    "    \n",
    "    # Make the plots\n",
    "    colors = plt.cm.get_cmap('tab10').colors\n",
    "    fig = plt.figure(figsize=(unit_size,numcols*unit_size))\n",
    "    ax = [None]*numcols \n",
    "    i = 0\n",
    "    for col_name in df.columns:\n",
    "        minVal = df[col_name].min()\n",
    "        maxVal = df[col_name].max()\n",
    "        \n",
    "        if col_name != class_name:                \n",
    "            ax[i] = fig.add_subplot(numcols,1,i+1)   \n",
    "            for j in range(classes):   \n",
    "                selectedCols = df[[col_name,class_name]]\n",
    "                filteredRows = selectedCols.loc[(df[class_name]==class_values[j])]\n",
    "                values = filteredRows[col_name]\n",
    "                values.plot(kind=plotType,ax=ax[i],color=[colors[j]], alpha = 0.8, label=class_values[j], range=(minVal,maxVal))\n",
    "                ax[i].set_title(col_name)\n",
    "                ax[i].grid() \n",
    "            ax[i].legend()\n",
    "            i += 1        \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def boxPlotAll(df):\n",
    "    '''Show box plots for each feature'''\n",
    "    \n",
    "    # Select just the numeric features\n",
    "    df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Compute the layout grid size\n",
    "    data_cols = len(df.columns)\n",
    "    unit_size = 5\n",
    "    layout_cols = 4\n",
    "    layout_rows = int(data_cols/layout_cols+layout_cols)\n",
    "\n",
    "    # Make the plots\n",
    "    df.plot(kind='box', subplots=True, figsize=(layout_cols*unit_size,layout_rows*unit_size), layout=(layout_rows,layout_cols))\n",
    "\n",
    "    plt.show()   \n",
    "        \n",
    "def histPlotAll(df):\n",
    "    '''Show histograms for each feature'''\n",
    "\n",
    "    # Select just the numeric features\n",
    "    df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Compute the layout grid size\n",
    "    data_cols = len(df.columns)\n",
    "    unit_size = 5\n",
    "    layout_cols = 4\n",
    "    layout_rows = int(data_cols/layout_cols+layout_cols)\n",
    "\n",
    "    # Make the plots\n",
    "    df.hist(figsize=(layout_cols*unit_size,layout_rows*unit_size), layout=(layout_rows,layout_cols))\n",
    "            \n",
    "    plt.show()               \n",
    "\n",
    "\n",
    "def correlationMatrix(df):\n",
    "    '''Show a correlation matrix for all features.'''\n",
    "    columns = df.select_dtypes(include=['float64','int64']).columns\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(df.corr(), vmin=-1, vmax=1, interpolation='none',cmap='RdYlBu')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticks(np.arange(len(columns)))\n",
    "    ax.set_yticks(np.arange(len(columns)))\n",
    "    ax.set_xticklabels(columns, rotation = 90)\n",
    "    ax.set_yticklabels(columns)\n",
    "    plt.show()   \n",
    "  \n",
    "\n",
    "def scatterMatrix(df):\n",
    "    '''Show a scatter matrix of all features.'''\n",
    "    unit_size = 5\n",
    "    pd.plotting.scatter_matrix(df,figsize=(unit_size*4, unit_size*4),  diagonal='kde')\n",
    "    plt.show()\n",
    "        \n",
    "\n",
    "def appendEqualCountsClass(df, class_name, feature, num_bins, labels):\n",
    "    '''Append a new class feature named 'class_name' based on a split of 'feature' into clases with equal sample points.  Class names are in 'labels'.'''\n",
    "\n",
    "    # Compute the bin boundaries\n",
    "    percentiles = np.linspace(0,100,num_bins+1)\n",
    "    bins = np.percentile(df[feature],percentiles)\n",
    "\n",
    "    # Split the data into bins\n",
    "    n = pd.cut(df[feature], bins = bins, labels=labels, include_lowest=True)\n",
    "\n",
    "    # Add the new binned feature to a copy of the data\n",
    "    c = df.copy()\n",
    "    c[class_name] = n\n",
    "    return c    \n",
    "\n",
    "def logisticRegressionSummary(model, column_names):\n",
    "    '''Show a summary of the trained logistic regression model'''\n",
    "\n",
    "    # Get a list of class names\n",
    "    numclasses = len(model.classes_)\n",
    "    if len(model.classes_)==2:\n",
    "        classes =  [model.classes_[1]] # if we have 2 classes, sklearn only shows one set of coefficients\n",
    "    else:\n",
    "        classes = model.classes_\n",
    "\n",
    "    # Create a plot for each class\n",
    "    for i,c in enumerate(classes):\n",
    "        # Plot the coefficients as bars\n",
    "        fig = plt.figure(figsize=(8,len(column_names)/3))\n",
    "        fig.suptitle('Logistic Regression Coefficients for Class ' + str(c), fontsize=16)\n",
    "        rects = plt.barh(column_names, model.coef_[i],color=\"lightblue\")\n",
    "        \n",
    "        # Annotate the bars with the coefficient values\n",
    "        for rect in rects:\n",
    "            width = round(rect.get_width(),4)\n",
    "            plt.gca().annotate('  {}  '.format(width),\n",
    "                        xy=(0, rect.get_y()),\n",
    "                        xytext=(0,2),  \n",
    "                        textcoords=\"offset points\",  \n",
    "                        ha='left' if width<0 else 'right', va='bottom')        \n",
    "        plt.show()\n",
    "        #for pair in zip(X.columns, model_lr.coef_[i]):\n",
    "        #    print (pair)\n",
    "\n",
    "def decisionTreeSummary(model, column_names):\n",
    "    '''Show a summary of the trained decision tree model'''\n",
    "\n",
    "    # Plot the feature importances as bars\n",
    "    fig = plt.figure(figsize=(8,len(column_names)/3))\n",
    "    fig.suptitle('Decision tree feature importance', fontsize=16)\n",
    "    rects = plt.barh(column_names, model.feature_importances_,color=\"khaki\")\n",
    "\n",
    "    # Annotate the bars with the feature importance values\n",
    "    for rect in rects:\n",
    "        width = round(rect.get_width(),4)\n",
    "        plt.gca().annotate('  {}  '.format(width),\n",
    "                    xy=(width, rect.get_y()),\n",
    "                    xytext=(0,2),  \n",
    "                    textcoords=\"offset points\",  \n",
    "                    ha='left', va='bottom')    \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def linearRegressionSummary(model, column_names):\n",
    "    '''Show a summary of the trained linear regression model'''\n",
    "\n",
    "    # Plot the coeffients as bars\n",
    "    fig = plt.figure(figsize=(8,len(column_names)/3))\n",
    "    fig.suptitle('Linear Regression Coefficients', fontsize=16)\n",
    "    rects = plt.barh(column_names, model.coef_,color=\"lightblue\")\n",
    "\n",
    "    # Annotate the bars with the coefficient values\n",
    "    for rect in rects:\n",
    "        width = round(rect.get_width(),4)\n",
    "        plt.gca().annotate('  {}  '.format(width),\n",
    "                    xy=(0, rect.get_y()),\n",
    "                    xytext=(0,2),  \n",
    "                    textcoords=\"offset points\",  \n",
    "                    ha='left' if width<0 else 'right', va='bottom')        \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def viewDecisionTree(model, column_names):\n",
    "    '''Visualise the decision tree'''\n",
    "\n",
    "    dot_data = tree.export_graphviz(model, out_file=None,\n",
    "            feature_names=column_names,\n",
    "            class_names=model.classes_,\n",
    "            filled=True, rounded=True,\n",
    "            special_characters=True)\n",
    "    graph = graphviz.Source(dot_data) \n",
    "    return graph    \n",
    "\n",
    "\n",
    "def find_outliers(feature):\n",
    "    '''Return a list of outliers in the data'''\n",
    "\n",
    "    # Temporarily replace nulls with mean so they don't cause an error\n",
    "    feature = feature.fillna(feature.mean()) \n",
    "\n",
    "    # Compute the quartiles\n",
    "    quartile_1, quartile_3 = np.percentile(feature, [25, 75])\n",
    "\n",
    "    # Compute the inter-quartile range\n",
    "    iqr = quartile_3 - quartile_1\n",
    "\n",
    "    # Compute the outlier boundaries\n",
    "    lower_bound = quartile_1 - (iqr * 1.5)\n",
    "    upper_bound = quartile_3 + (iqr * 1.5)\n",
    "\n",
    "    # Return rows where the feature is outside the outlier boundaries\n",
    "    return np.where((feature > upper_bound) | (feature < lower_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53144765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
